{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst || SQL,Python, R || Bangalore</td>\n",
       "      <td>Binary Semantics Limited</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst PowerBI Bangalore</td>\n",
       "      <td>Talent Corner HR Services Pvt Ltd</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bion</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - I</td>\n",
       "      <td>Novel Office</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Perficient India Private Limited</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Chennai, Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hiring Data Analysts on Contract</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hiring Data Analysts on Contract</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Liventus, Inc.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>Bengaluru(2nd Phase JP Nagar)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Looking For Rockstar Data Analyst @ Freshtohom...</td>\n",
       "      <td>Freshtohome Foods Private Limited</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SAP Data Analyst</td>\n",
       "      <td>JOHN CRANE SEALING SYSTEMS INDIA PVT. LTD.</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bengaluru</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0         Data Analyst || SQL,Python, R || Bangalore   \n",
       "1                     Data Analyst PowerBI Bangalore   \n",
       "2                                       Data Analyst   \n",
       "3                                   Data Analyst - I   \n",
       "4                                       Data Analyst   \n",
       "5                   Hiring Data Analysts on Contract   \n",
       "6                   Hiring Data Analysts on Contract   \n",
       "7                                       Data Analyst   \n",
       "8  Looking For Rockstar Data Analyst @ Freshtohom...   \n",
       "9                                   SAP Data Analyst   \n",
       "\n",
       "                                      company experience_required  \\\n",
       "0                    Binary Semantics Limited             3-7 Yrs   \n",
       "1           Talent Corner HR Services Pvt Ltd             1-3 Yrs   \n",
       "2                                        Bion             2-4 Yrs   \n",
       "3                                Novel Office             0-3 Yrs   \n",
       "4            Perficient India Private Limited             3-8 Yrs   \n",
       "5           Flipkart Internet Private Limited             2-5 Yrs   \n",
       "6           Flipkart Internet Private Limited             2-5 Yrs   \n",
       "7                              Liventus, Inc.             3-6 Yrs   \n",
       "8           Freshtohome Foods Private Limited             2-5 Yrs   \n",
       "9  JOHN CRANE SEALING SYSTEMS INDIA PVT. LTD.             3-7 Yrs   \n",
       "\n",
       "                        location  \n",
       "0                      Bengaluru  \n",
       "1          Bengaluru / Bangalore  \n",
       "2                      Bengaluru  \n",
       "3                      Bengaluru  \n",
       "4             Chennai, Bengaluru  \n",
       "5                      Bengaluru  \n",
       "6                      Bengaluru  \n",
       "7  Bengaluru(2nd Phase JP Nagar)  \n",
       "8                      Bengaluru  \n",
       "9                      Bengaluru  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "#finding element for job search bar\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Analyst\")\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url=(\"https://www.naukri.com/data-analyst-jobs-in-bangalore?k=data%20analyst&l=bangalore\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url)\n",
    "\n",
    "#creating empty list\n",
    "job_titles=[]\n",
    "company_names=[]\n",
    "location_list=[]\n",
    "experience_list=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_names.append(company_name)\n",
    "    \n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_list.append(location_name)\n",
    "\n",
    "#finding tags of the experience names\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "\n",
    "#finding text element in experience tags\n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "\n",
    "#creating a dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs[\"title\"]=job_titles[:10]\n",
    "jobs[\"company\"]=company_names[:10]\n",
    "jobs[\"experience_required\"]=experience_list[:10]\n",
    "jobs[\"location\"]=location_list[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist - Python/sql</td>\n",
       "      <td>Catalyst</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job description\\n\\nSkill: SQL, Python, Busines...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Python/ MATLAB/ Machine Learn...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Data Scientist - Data Mining/ Machine Learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lead Data Scientist - Machine Learning/ Data M...</td>\n",
       "      <td>Wrackle Technologies Pvt Ltd</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Roles and Responsibilities\\nRequirements :\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Principal Data Scientist - Machine/Deep Learni...</td>\n",
       "      <td>Fidius advisory</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Job Description :\\n- We are looking for a rese...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Atos Syntel Private Limited</td>\n",
       "      <td>Chennai, Pune, Mumbai, Bengaluru</td>\n",
       "      <td>Working experience in Artificial Intelligence,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>TVS CREDIT SERVICES LIMITED</td>\n",
       "      <td>Chennai, Pune, Bengaluru</td>\n",
       "      <td>Key Responsibilities\\nBe responsible for scali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist - NLP/ Python/ R</td>\n",
       "      <td>AVI Consulting LLP</td>\n",
       "      <td>Bengaluru, Hyderabad</td>\n",
       "      <td>Roles and Responsibilities\\nSkill : NLP,Semant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist | CES IT LTD | CMMI Level 5</td>\n",
       "      <td>CES Ltd.</td>\n",
       "      <td>Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...</td>\n",
       "      <td>Roles and Responsibilities\\n\\nMust have strong...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist and Senior Data Scientist Acade...</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>We are hiring Data Scientist and Senior Data S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Analyst-Data Scientist</td>\n",
       "      <td>Mindtree Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Role Description:\\nA Sr. Data Scientist who le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                        Data Scientist - Python/sql   \n",
       "1  Data Scientist - Python/ MATLAB/ Machine Learn...   \n",
       "2  Lead Data Scientist - Machine Learning/ Data M...   \n",
       "3  Principal Data Scientist - Machine/Deep Learni...   \n",
       "4                                     Data Scientist   \n",
       "5                       Senior / Lead Data Scientist   \n",
       "6             Senior Data Scientist - NLP/ Python/ R   \n",
       "7  Senior Data Scientist | CES IT LTD | CMMI Level 5   \n",
       "8  Data Scientist and Senior Data Scientist Acade...   \n",
       "9                         Sr. Analyst-Data Scientist   \n",
       "\n",
       "                        company  \\\n",
       "0                      Catalyst   \n",
       "1  Wrackle Technologies Pvt Ltd   \n",
       "2  Wrackle Technologies Pvt Ltd   \n",
       "3               Fidius advisory   \n",
       "4   Atos Syntel Private Limited   \n",
       "5   TVS CREDIT SERVICES LIMITED   \n",
       "6            AVI Consulting LLP   \n",
       "7                      CES Ltd.   \n",
       "8        RANDSTAD INDIA PVT LTD   \n",
       "9              Mindtree Limited   \n",
       "\n",
       "                                            location  \\\n",
       "0                                          Bengaluru   \n",
       "1                                          Bengaluru   \n",
       "2                                          Bengaluru   \n",
       "3                                          Bengaluru   \n",
       "4                   Chennai, Pune, Mumbai, Bengaluru   \n",
       "5                           Chennai, Pune, Bengaluru   \n",
       "6                               Bengaluru, Hyderabad   \n",
       "7  Chennai, Pune, Delhi NCR, Mumbai, Bengaluru, H...   \n",
       "8                                          Bengaluru   \n",
       "9                                          Bengaluru   \n",
       "\n",
       "                                     job_description  \n",
       "0  Job description\\n\\nSkill: SQL, Python, Busines...  \n",
       "1  Data Scientist - Data Mining/ Machine Learning...  \n",
       "2  Roles and Responsibilities\\nRequirements :\\n\\n...  \n",
       "3  Job Description :\\n- We are looking for a rese...  \n",
       "4  Working experience in Artificial Intelligence,...  \n",
       "5  Key Responsibilities\\nBe responsible for scali...  \n",
       "6  Roles and Responsibilities\\nSkill : NLP,Semant...  \n",
       "7  Roles and Responsibilities\\n\\nMust have strong...  \n",
       "8  We are hiring Data Scientist and Senior Data S...  \n",
       "9  Role Description:\\nA Sr. Data Scientist who le...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "\n",
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "#finding element for job search bar\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "search_loc=driver.find_element_by_xpath(\"//input[@id='qsb-location-sugg']\")\n",
    "search_loc.send_keys(\"Bangalore\")\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url1=(\"https://www.naukri.com/job-listings-data-scientist-python-sql-catalyst-bengaluru-bangalore-2-to-7-years-081119903383?src=jobsearchDesk&sid=16131618602304001&xp=1&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url1)\n",
    "\n",
    "#creating empty list\n",
    "job_name_1=[]\n",
    "company_name_1=[]\n",
    "location_name_1=[]\n",
    "job_description_1=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_1.append(title)\n",
    "    \n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_1.append(company_name)\n",
    "company_name_1=company_name_1[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_1.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_1.append(job_description)\n",
    "job_description_1=job_description_1[:1]\n",
    "\n",
    "jobs_1=pd.DataFrame({})\n",
    "jobs_1[\"title\"]=job_name_1\n",
    "jobs_1[\"company\"]=company_name_1\n",
    "jobs_1[\"location\"]=location_name_1\n",
    "jobs_1[\"job_description\"]=job_description_1\n",
    "\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url2=(\"https://www.naukri.com/job-listings-data-scientist-python-matlab-machine-learning-algorithms-wrackle-technologies-pvt-ltd-bengaluru-bangalore-3-to-8-years-080221905947?src=jobsearchDesk&sid=16131666921196657&xp=1&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url2)\n",
    "\n",
    "#creating empty list\n",
    "job_name_2=[]\n",
    "company_name_2=[]\n",
    "location_name_2=[]\n",
    "job_description_2=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_2.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_2.append(company_name)\n",
    "company_name_2=company_name_2[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_2.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "job_description_tags\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_2.append(job_description)\n",
    "job_description_2=job_description_2[:1]\n",
    "\n",
    "jobs_2=pd.DataFrame({})\n",
    "jobs_2[\"title\"]=job_name_2\n",
    "jobs_2[\"company\"]=company_name_2\n",
    "jobs_2[\"location\"]=location_name_2\n",
    "jobs_2[\"job_description\"]=job_description_2\n",
    "\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url3=(\"https://www.naukri.com/job-listings-lead-data-scientist-machine-learning-data-mining-wrackle-technologies-pvt-ltd-bengaluru-bangalore-6-to-11-years-080221900886?src=jobsearchDesk&sid=16131672806199684&xp=2&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url3)\n",
    "\n",
    "#creating empty list\n",
    "job_name_3=[]\n",
    "company_name_3=[]\n",
    "location_name_3=[]\n",
    "job_description_3=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_3.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_3.append(company_name)\n",
    "company_name_3=company_name_3[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_3.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_3.append(job_description)\n",
    "job_description_3=job_description_3[:1]\n",
    "\n",
    "jobs_3=pd.DataFrame({})\n",
    "jobs_3[\"title\"]=job_name_3\n",
    "jobs_3[\"company\"]=company_name_3\n",
    "jobs_3[\"location\"]=location_name_3\n",
    "jobs_3[\"job_description\"]=job_description_3\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url4=(\"https://www.naukri.com/job-listings-principal-data-scientist-machine-deep-learning-nlp-tensorflow-fidius-advisory-bengaluru-bangalore-8-to-13-years-070720900498?src=jobsearchDesk&sid=16131682972292745&xp=4&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url4)\n",
    "\n",
    "#creating empty list\n",
    "job_name_4=[]\n",
    "company_name_4=[]\n",
    "location_name_4=[]\n",
    "job_description_4=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_4.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_4.append(company_name)\n",
    "company_name_4=company_name_4[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_4.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_4.append(job_description)\n",
    "job_description_4=job_description_4[:1]\n",
    "\n",
    "jobs_4=pd.DataFrame({})\n",
    "jobs_4[\"title\"]=job_name_4\n",
    "jobs_4[\"company\"]=company_name_4\n",
    "jobs_4[\"location\"]=location_name_4\n",
    "jobs_4[\"job_description\"]=job_description_4\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url5=(\"https://www.naukri.com/job-listings-data-scientist-atos-syntel-private-limited-chennai-pune-mumbai-bengaluru-bangalore-12-to-18-years-220719001543?src=jobsearchDesk&sid=16131686888815822&xp=5&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url5)\n",
    "\n",
    "#creating empty list\n",
    "job_name_5=[]\n",
    "company_name_5=[]\n",
    "location_name_5=[]\n",
    "job_description_5=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_5.append(title)\n",
    "    \n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_5.append(company_name)\n",
    "company_name_5=company_name_5[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_5.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_5.append(job_description)\n",
    "job_description_5=job_description_5[:1]\n",
    "\n",
    "jobs_5=pd.DataFrame({})\n",
    "jobs_5[\"title\"]=job_name_5\n",
    "jobs_5[\"company\"]=company_name_5\n",
    "jobs_5[\"location\"]=location_name_5\n",
    "jobs_5[\"job_description\"]=job_description_5\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url6=(\"https://www.naukri.com/job-listings-senior-lead-data-scientist-tvs-credit-services-limited-chennai-pune-bengaluru-bangalore-3-to-8-years-261220002239?src=jobsearchDesk&sid=16131699479845590&xp=8&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url6)\n",
    "\n",
    "#creating empty list\n",
    "job_name_6=[]\n",
    "company_name_6=[]\n",
    "location_name_6=[]\n",
    "job_description_6=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_6.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_6.append(company_name)\n",
    "company_name_6=company_name_6[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_6.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_6.append(job_description)\n",
    "job_description_6=job_description_6[:1]\n",
    "\n",
    "jobs_6=pd.DataFrame({})\n",
    "jobs_6[\"title\"]=job_name_6\n",
    "jobs_6[\"company\"]=company_name_6\n",
    "jobs_6[\"location\"]=location_name_6\n",
    "jobs_6[\"job_description\"]=job_description_6\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url7=(\"https://www.naukri.com/job-listings-senior-data-scientist-nlp-python-r-avi-consulting-llp-bengaluru-bangalore-hyderabad-secunderabad-4-to-9-years-081220907155?src=jobsearchDesk&sid=16131702209617368&xp=9&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url7)\n",
    "\n",
    "#creating empty list\n",
    "job_name_7=[]\n",
    "company_name_7=[]\n",
    "location_name_7=[]\n",
    "job_description_7=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_7.append(title)\n",
    "    \n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_7.append(company_name)\n",
    "company_name_7=company_name_7[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_7.append(location_name)\n",
    "    \n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_7.append(job_description)\n",
    "job_description_7=job_description_7[:1]\n",
    "\n",
    "jobs_7=pd.DataFrame({})\n",
    "jobs_7[\"title\"]=job_name_7\n",
    "jobs_7[\"company\"]=company_name_7\n",
    "jobs_7[\"location\"]=location_name_7\n",
    "jobs_7[\"job_description\"]=job_description_7\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url8=(\"https://www.naukri.com/job-listings-senior-data-scientist-ces-it-ltd-cmmi-level-5-ces-ltd-chennai-pune-delhi-ncr-mumbai-bengaluru-bangalore-hyderabad-secunderabad-kolkata-2-to-7-years-151220006902?src=jobsearchDesk&sid=16131705275458060&xp=10&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url8)\n",
    "\n",
    "#creating empty list\n",
    "job_name_8=[]\n",
    "company_name_8=[]\n",
    "location_name_8=[]\n",
    "job_description_8=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_8.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_8.append(company_name)\n",
    "company_name_8=company_name_8[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_8.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_8.append(job_description)\n",
    "job_description_8=job_description_8[:1]\n",
    "\n",
    "jobs_8=pd.DataFrame({})\n",
    "jobs_8[\"title\"]=job_name_8\n",
    "jobs_8[\"company\"]=company_name_8\n",
    "jobs_8[\"location\"]=location_name_8\n",
    "jobs_8[\"job_description\"]=job_description_8\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url9=(\"https://www.naukri.com/job-listings-data-scientist-and-senior-data-scientist-academic-operations-randstad-india-pvt-ltd-bengaluru-bangalore-2-to-5-years-080221007079?src=jobsearchDesk&sid=16131711302642736&xp=11&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url9)\n",
    "\n",
    "#creating empty list\n",
    "job_name_9=[]\n",
    "company_name_9=[]\n",
    "location_name_9=[]\n",
    "job_description_9=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_9.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_9.append(company_name)\n",
    "company_name_9=company_name_9[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_9.append(location_name)\n",
    "\n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_9.append(job_description)\n",
    "job_description_9=job_description_9[:1]\n",
    "\n",
    "jobs_9=pd.DataFrame({})\n",
    "jobs_9[\"title\"]=job_name_9\n",
    "jobs_9[\"company\"]=company_name_9\n",
    "jobs_9[\"location\"]=location_name_9\n",
    "jobs_9[\"job_description\"]=job_description_9\n",
    "\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url10=(\"https://www.naukri.com/job-listings-sr-analyst-data-scientist-mindtree-limited-bengaluru-bangalore-10-to-15-years-040221502130?src=jobsearchDesk&sid=16131713670108924&xp=12&px=1\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url10)\n",
    "\n",
    "#creating empty list\n",
    "job_name_10=[]\n",
    "company_name_10=[]\n",
    "location_name_10=[]\n",
    "job_description_10=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//h1[@class='jd-header-title']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_name_10.append(title)\n",
    "    \n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='pad-rt-8']\")\n",
    "\n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_name_10.append(company_name)\n",
    "company_name_10=company_name_10[:1]\n",
    "\n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_class_name(\"location\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_name_10.append(location_name)\n",
    "    \n",
    "#finding text element in job description tags\n",
    "job_description_tags=driver.find_elements_by_class_name(\"dang-inner-html\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in job_description_tags:\n",
    "    job_description=i.text\n",
    "    job_description_10.append(job_description)\n",
    "job_description_10=job_description_10[:1]\n",
    "\n",
    "jobs_10=pd.DataFrame({})\n",
    "jobs_10[\"title\"]=job_name_10\n",
    "jobs_10[\"company\"]=company_name_10\n",
    "jobs_10[\"location\"]=location_name_10\n",
    "jobs_10[\"job_description\"]=job_description_10\n",
    "\n",
    "#combining two data frames\n",
    "frames=[jobs_1,jobs_2,jobs_3,jobs_4,jobs_5,jobs_6,jobs_7,jobs_8,jobs_9,jobs_10]\n",
    "result=pd.concat(frames,ignore_index=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name, experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>IBM India Pvt. Limited</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Only Fresher / Data Scientist / Data Analyst /...</td>\n",
       "      <td>GABA Consultancy services</td>\n",
       "      <td>0-0 Yrs</td>\n",
       "      <td>Delhi NCR, Noida, Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Ciena</td>\n",
       "      <td>5-6 Yrs</td>\n",
       "      <td>Gurgaon Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist Machine Learning</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Business Analyst - Data Scientist</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analyst - Data Scientist</td>\n",
       "      <td>HyreFox Consultants Pvt Ltd</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Amity University</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "      <td>Faridabad, Delhi NCR, Ghaziabad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>Bengaluru, Gurgaon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>iNICU</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>Delhi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                     Data Scientist   \n",
       "1  Only Fresher / Data Scientist / Data Analyst /...   \n",
       "2                                     Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                    Data Scientist Machine Learning   \n",
       "5                  Business Analyst - Data Scientist   \n",
       "6                           Analyst - Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                              Senior Data Scientist   \n",
       "\n",
       "                       company experience_required  \\\n",
       "0       IBM India Pvt. Limited             4-8 Yrs   \n",
       "1    GABA Consultancy services             0-0 Yrs   \n",
       "2                        Ciena             5-6 Yrs   \n",
       "3               Country Veggie             1-3 Yrs   \n",
       "4                    Delhivery             1-3 Yrs   \n",
       "5  HyreFox Consultants Pvt Ltd             3-5 Yrs   \n",
       "6  HyreFox Consultants Pvt Ltd             1-3 Yrs   \n",
       "7             Amity University             6-8 Yrs   \n",
       "8                    BlackBuck             3-7 Yrs   \n",
       "9                        iNICU             1-5 Yrs   \n",
       "\n",
       "                                            location  \n",
       "0                                   Gurgaon Gurugram  \n",
       "1                          Delhi NCR, Noida, Gurgaon  \n",
       "2                                   Gurgaon Gurugram  \n",
       "3  Ghaziabad, Bhopal, Lucknow, Kanpur, Rajkot, Be...  \n",
       "4                                            Gurgaon  \n",
       "5                                            Gurgaon  \n",
       "6                                            Gurgaon  \n",
       "7                    Faridabad, Delhi NCR, Ghaziabad  \n",
       "8                                 Bengaluru, Gurgaon  \n",
       "9                                              Delhi  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "\n",
    "#finding element for job search bar\n",
    "search_job=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "#clicking the search button\n",
    "search_btn=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_btn.click()\n",
    "\n",
    "#specifying the url of the web page that needs to be scraped\n",
    "url=(\"https://www.naukri.com/data-scientist-jobs?k=data%20scientist&ctcFilter=3to6&cityType=25.9.31\")\n",
    "\n",
    "#getting driver of the url\n",
    "driver.get(url)\n",
    "\n",
    "#creating empty list\n",
    "job_titles=[]\n",
    "company_names=[]\n",
    "location_list=[]\n",
    "experience_list=[]\n",
    "\n",
    "#finding tags of job titles\n",
    "titles_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "\n",
    "#finding text element in the job title tags\n",
    "for i in titles_tags:\n",
    "    title=i.text\n",
    "    job_titles.append(title)\n",
    "\n",
    "#finding tags of company names\n",
    "company_name_tags=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "    \n",
    "#finding text element in company name tags\n",
    "for i in company_name_tags:\n",
    "    company_name=i.text\n",
    "    company_names.append(company_name)\n",
    "    \n",
    "#finding tags of the location names\n",
    "location_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "\n",
    "#finding text element in location tags\n",
    "for i in location_tags:\n",
    "    location_name=i.text\n",
    "    location_list.append(location_name)\n",
    "    \n",
    "#finding tags of the experience names\n",
    "experience_tags=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "\n",
    "#finding text element in experience tags\n",
    "for i in experience_tags:\n",
    "    experience=i.text\n",
    "    experience_list.append(experience)\n",
    "\n",
    "#creating a dataframe\n",
    "jobs=pd.DataFrame({})\n",
    "jobs[\"title\"]=job_titles[:10]\n",
    "jobs[\"company\"]=company_names[:10]\n",
    "jobs[\"experience_required\"]=experience_list[:10]\n",
    "jobs[\"location\"]=location_list[:10]\n",
    "jobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. These are\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review\n",
    "You have to scrape this data for first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_summary</th>\n",
       "      <th>full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>*Review after 10 months of usage*\\nDoesn't see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Nice product</td>\n",
       "      <td>Awesome Phone. Slightly high price but worth. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating      review_summary  \\\n",
       "0       5    Perfect product!   \n",
       "1       5       Great product   \n",
       "2       5  Highly recommended   \n",
       "3       5    Perfect product!   \n",
       "4       5           Brilliant   \n",
       "..    ...                 ...   \n",
       "95      5    Perfect product!   \n",
       "96      5   Worth every penny   \n",
       "97      5   Worth every penny   \n",
       "98      5           Wonderful   \n",
       "99      4        Nice product   \n",
       "\n",
       "                                          full_review  \n",
       "0   Amazing phone with great cameras and better ba...  \n",
       "1   Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "2   iphone 11 is a very good phone to buy only if ...  \n",
       "3   It’s a must buy who is looking for an upgrade ...  \n",
       "4   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "..                                                ...  \n",
       "95  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "96  Best budget Iphone till date ❤️ go for it guys...  \n",
       "97  It’s been almost a month since I have been usi...  \n",
       "98  *Review after 10 months of usage*\\nDoesn't see...  \n",
       "99  Awesome Phone. Slightly high price but worth. ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty list\n",
    "rating=[]\n",
    "review_summary=[]\n",
    "full_review=[]\n",
    "\n",
    "#getting the webdriver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the page url\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGR3QP11A&marketplace=FLIPKART\")\n",
    "\n",
    "for page in range(0,11):\n",
    "    \n",
    "    #getting tags for the ratings\n",
    "    rating_tags=driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\")\n",
    "    \n",
    "    #geting tags for the reviews\n",
    "    review_tags=driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\")\n",
    "    \n",
    "    #getting tags for the full reviews\n",
    "    full_review_tags=driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']\")\n",
    "    \n",
    "    #getting text element from the rating tags\n",
    "    for i in rating_tags:\n",
    "        ratings=i.text\n",
    "        rating.append(ratings)\n",
    "    \n",
    "    #getting text element from the review tags\n",
    "    for i in review_tags:\n",
    "        reviews=i.text\n",
    "        review_summary.append(reviews)\n",
    "    \n",
    "    #getting text element from the full review tags\n",
    "    for i in full_review_tags:\n",
    "        full=i.text\n",
    "        full_review.append(full)\n",
    "    \n",
    "Iphone=pd.DataFrame({})\n",
    "Iphone[\"rating\"]=rating[:100]\n",
    "Iphone[\"review_summary\"]=review_summary[:100]\n",
    "Iphone[\"full_review\"]=full_review[:100]\n",
    "Iphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise  6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "#finding element for job search bar\n",
    "search_job=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_job.send_keys(\"Sunglasses\")\n",
    "\n",
    "#clicking the search button\n",
    "search_btn=driver.find_element_by_class_name(\"L0Z3Pu\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_description</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Aviator Sunglasses (88)</td>\n",
       "      <td>₹255</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹246</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹499</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹499</td>\n",
       "      <td>37% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>33% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, Mirrored, UV Protection Round, Round...</td>\n",
       "      <td>₹404</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>shah collections</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹398</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer, Aviator Sunglasses (88)</td>\n",
       "      <td>₹399</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>Night Vision, Polarized, UV Protection, Riding...</td>\n",
       "      <td>₹314</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               brand                                product_description price  \\\n",
       "0       Silver Kartz              UV Protection Aviator Sunglasses (88)  ₹255   \n",
       "1       Silver Kartz      UV Protection Wayfarer Sunglasses (Free Size)  ₹246   \n",
       "2     ROZZETTA CRAFT  UV Protection Retro Square Sunglasses (Free Size)  ₹499   \n",
       "3           Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "4           Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹499   \n",
       "..               ...                                                ...   ...   \n",
       "95          Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹599   \n",
       "96          Fastrack  Gradient, Mirrored, UV Protection Round, Round...  ₹404   \n",
       "97  shah collections              UV Protection Aviator Sunglasses (58)  ₹398   \n",
       "98          Fastrack    UV Protection Wayfarer, Aviator Sunglasses (88)  ₹399   \n",
       "99      Silver Kartz  Night Vision, Polarized, UV Protection, Riding...  ₹314   \n",
       "\n",
       "   discount  \n",
       "0   78% off  \n",
       "1   83% off  \n",
       "2   77% off  \n",
       "3   37% off  \n",
       "4   37% off  \n",
       "..      ...  \n",
       "95  33% off  \n",
       "96  79% off  \n",
       "97  73% off  \n",
       "98  80% off  \n",
       "99  80% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#creating a loop for the page numbers\n",
    "for page in range(0,4):\n",
    "    \n",
    "    #finding tags for brand names\n",
    "    brand_name_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    \n",
    "    #finding tags for product description\n",
    "    product_description_tags=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    #finding tags for price\n",
    "    price_tags=driver.find_elements_by_class_name(\"_30jeq3\")\n",
    "    \n",
    "    #finding tags for discount\n",
    "    discount_tags=driver.find_elements_by_class_name(\"_3Ay6Sb\")\n",
    "    \n",
    "    #finding text element in brand tags \n",
    "    for i in brand_name_tags:\n",
    "        brand_name=i.text\n",
    "        brand.append(brand_name)\n",
    "        \n",
    "    #finding text element in description tags   \n",
    "    for i in product_description_tags:\n",
    "        product=i.text\n",
    "        product_description.append(product)\n",
    "        \n",
    "    #finding text element in price tags     \n",
    "    for i in price_tags:\n",
    "        prices=i.text\n",
    "        price.append(prices)\n",
    "    \n",
    "     #finding text element in discount tags \n",
    "    for i in discount_tags:\n",
    "        dis=i.text\n",
    "        discount.append(dis)\n",
    "        \n",
    "#creating a dataframe\n",
    "Sunglass=pd.DataFrame({})\n",
    "Sunglass[\"brand\"]=brand[:100]\n",
    "Sunglass[\"product_description\"]=product_description[:100]\n",
    "Sunglass[\"price\"]=price[:100]\n",
    "Sunglass[\"discount\"]=discount[:100]\n",
    "Sunglass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "#finding element for job search bar\n",
    "search_job=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_job.send_keys(\"sneakers\")\n",
    "\n",
    "#clicking the search button\n",
    "search_btn=driver.find_element_by_class_name(\"L0Z3Pu\")\n",
    "search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product_description</th>\n",
       "      <th>price</th>\n",
       "      <th>discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wildcraft</td>\n",
       "      <td>Nova Sneakers For Men</td>\n",
       "      <td>₹1,677</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMROX</td>\n",
       "      <td>Combo Pack of 4 Casual Sneakers With Sneakers ...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>73% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>LeatherKraft</td>\n",
       "      <td>Combo Pack of 4 Latest Collection Stylish Casu...</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Restinfoot</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Axter</td>\n",
       "      <td>White Sneaker For Men's/Boy's Sneakers For Men</td>\n",
       "      <td>₹236</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>171 Smart Tan Lace-Ups Casuals for Men Sneaker...</td>\n",
       "      <td>₹242</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  brand                                product_description  \\\n",
       "0             Wildcraft                              Nova Sneakers For Men   \n",
       "1                 AMROX  Combo Pack of 4 Casual Sneakers With Sneakers ...   \n",
       "2                Chevit  Combo Pack of 4 Latest Collection Stylish Casu...   \n",
       "3          Robbie jones  Combo pack of 2 casual sneaker shoes for men S...   \n",
       "4   World Wear Footwear     White Sneaker For Men's/Boy's Sneakers For Men   \n",
       "..                  ...                                                ...   \n",
       "95         LeatherKraft  Combo Pack of 4 Latest Collection Stylish Casu...   \n",
       "96           Restinfoot  Combo pack of 2 casual sneaker shoes for men S...   \n",
       "97                Axter     White Sneaker For Men's/Boy's Sneakers For Men   \n",
       "98               BRUTON  171 Smart Tan Lace-Ups Casuals for Men Sneaker...   \n",
       "99             Red Tape                                   Sneakers For Men   \n",
       "\n",
       "     price discount  \n",
       "0   ₹1,677  52% off  \n",
       "1     ₹399  73% off  \n",
       "2     ₹474  76% off  \n",
       "3     ₹399  60% off  \n",
       "4     ₹474  76% off  \n",
       "..     ...      ...  \n",
       "95    ₹398  60% off  \n",
       "96    ₹349  65% off  \n",
       "97    ₹236  52% off  \n",
       "98    ₹242  65% off  \n",
       "99    ₹379  62% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "#creating a loop for the page numbers\n",
    "for page in range(0,4):\n",
    "    \n",
    "    #finding tags for brand names\n",
    "    brand_name_tags=driver.find_elements_by_xpath(\"//div[@class='_2WkVRV']\")\n",
    "    \n",
    "    #finding tags for product description\n",
    "    product_description_tags=driver.find_elements_by_xpath(\"//a[@class='IRpwTa']\")\n",
    "    \n",
    "    #finding tags for price\n",
    "    price_tags=driver.find_elements_by_class_name(\"_30jeq3\")\n",
    "    \n",
    "    #finding tags for discount\n",
    "    discount_tags=driver.find_elements_by_class_name(\"_3Ay6Sb\")\n",
    "    \n",
    "    #finding text element in brand tags \n",
    "    for i in brand_name_tags:\n",
    "        brand_name=i.text\n",
    "        brand.append(brand_name)\n",
    "        \n",
    "    #finding text element in description tags   \n",
    "    for i in product_description_tags:\n",
    "        product=i.text\n",
    "        product_description.append(product)\n",
    "        \n",
    "    #finding text element in price tags     \n",
    "    for i in price_tags:\n",
    "        prices=i.text\n",
    "        price.append(prices)\n",
    "    \n",
    "     #finding text element in discount tags \n",
    "    for i in discount_tags:\n",
    "        dis=i.text\n",
    "        discount.append(dis)\n",
    "        \n",
    "#creating a dataframe\n",
    "Sneakers=pd.DataFrame({})\n",
    "Sneakers[\"brand\"]=brand[:100]\n",
    "Sneakers[\"product_description\"]=product_description[:100]\n",
    "Sneakers[\"price\"]=price[:100]\n",
    "Sneakers[\"discount\"]=discount[:100]\n",
    "Sneakers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9: Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” , Color filter to “Black”, And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe as shown in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting with the web driver\n",
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "\n",
    "#getting the url\n",
    "driver.get(\" https://www.myntra.com/shoes\")\n",
    "\n",
    "#clicking the price filter\n",
    "price_btn=driver.find_element_by_class_name(\"price-num\")\n",
    "driver.execute_script(\"arguments[0].click();\", price_btn)\n",
    "\n",
    "#clicking the colour filter\n",
    "colour_btn=driver.find_element_by_class_name(\"colour-num\")\n",
    "driver.execute_script(\"arguments[0].click();\", colour_btn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN ZOOM '92 Shoes</td>\n",
       "      <td>Rs. 10796Rs. 13495(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JORDAN DELTA Basketball</td>\n",
       "      <td>Rs. 12495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men JOYRIDE Running Shoes</td>\n",
       "      <td>Rs. 11996Rs. 14995(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men AIR ZOOM VOMERO Running</td>\n",
       "      <td>Rs. 10796Rs. 13495(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Men SOLAR DRIVE 19 M Running</td>\n",
       "      <td>Rs. 8399Rs. 11999(30% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Women Leather Pumps</td>\n",
       "      <td>Rs. 7192Rs. 8990(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Hush Puppies</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Men Wingtip Oxford Sneakers</td>\n",
       "      <td>Rs. 12999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Reebok</td>\n",
       "      <td>Women Flexagon Training Shoes</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Textured Derbys</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   brand                    description  \\\n",
       "0                   Nike      Men JORDAN ZOOM '92 Shoes   \n",
       "1                   Nike    Men JORDAN DELTA Basketball   \n",
       "2                   Nike      Men JOYRIDE Running Shoes   \n",
       "3                   Nike    Men AIR ZOOM VOMERO Running   \n",
       "4                 ADIDAS   Men SOLAR DRIVE 19 M Running   \n",
       "..                   ...                            ...   \n",
       "95  Heel & Buckle London            Women Leather Pumps   \n",
       "96          Hush Puppies            Men Leather Loafers   \n",
       "97             Cole Haan    Men Wingtip Oxford Sneakers   \n",
       "98                Reebok  Women Flexagon Training Shoes   \n",
       "99                 Ruosh            Men Textured Derbys   \n",
       "\n",
       "                          price  \n",
       "0   Rs. 10796Rs. 13495(20% OFF)  \n",
       "1                     Rs. 12495  \n",
       "2   Rs. 11996Rs. 14995(20% OFF)  \n",
       "3   Rs. 10796Rs. 13495(20% OFF)  \n",
       "4    Rs. 8399Rs. 11999(30% OFF)  \n",
       "..                          ...  \n",
       "95    Rs. 7192Rs. 8990(20% OFF)  \n",
       "96                     Rs. 6999  \n",
       "97                    Rs. 12999  \n",
       "98                     Rs. 7999  \n",
       "99                     Rs. 8990  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating empty lists\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "\n",
    "#creating a for loop for the pages\n",
    "for page in range(0,4):\n",
    "    \n",
    "    #getting tags for the brand\n",
    "    brand_tags=driver.find_elements_by_xpath(\"//h3[@class='product-brand']\")\n",
    "    \n",
    "    #getting tags for the description\n",
    "    description_tags=driver.find_elements_by_xpath(\"//h4[@class='product-product']\")\n",
    "    \n",
    "    #getting tags for he prices\n",
    "    price_tags=driver.find_elements_by_xpath(\"//div[@class='product-price']\")\n",
    "    \n",
    "    #getting text element in the brand tags\n",
    "    for i in brand_tags:\n",
    "        brand_name=i.text\n",
    "        brand.append(brand_name)\n",
    "    \n",
    "    #getting text element in the description tags\n",
    "    for i in description_tags:\n",
    "        des=i.text\n",
    "        description.append(des)\n",
    "    \n",
    "    #getting text element in the price tags\n",
    "    for i in price_tags:\n",
    "        prices=i.text\n",
    "        price.append(prices)\n",
    "\n",
    "#creating dataframe        \n",
    "Shoes=pd.DataFrame({})\n",
    "Shoes[\"brand\"]=brand[:100]\n",
    "Shoes[\"description\"]=description[:100]\n",
    "Shoes[\"price\"]=price[:100]\n",
    "Shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.common.exceptions import ElementNotInteractableException\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(\"C:\\Program Files\\chromedriver.exe\")\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "time.sleep(5)\n",
    "try:\n",
    "    search_bar=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "    search_bar.send_keys(\"Laptop\")\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception Raised: \",e)\n",
    "    search_bar=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "    search_bar.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    search_click=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "    search_click.click()\n",
    "except ElementNotInteractableException as e:\n",
    "    print(\"Exception Raised: \",e)\n",
    "    search_click=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "    search_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_click=driver.find_element_by_xpath(\"//i[@class='a-icon a-icon-checkbox']\")\n",
    "search_click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "ratings_tags=driver.find_elements_by_xpath(\"//span[@class='a-icon-alt']/span\")\n",
    "price_tags=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty lists\n",
    "Titles=[]\n",
    "Ratings=[]\n",
    "Prices=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in title_tags:\n",
    "        title=i.text\n",
    "        Titles.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ratings_tags:\n",
    "        rating=i.text\n",
    "        Ratings.append(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in price_tags:\n",
    "        prices=i.text\n",
    "        Prices.append(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (0) does not match length of index (10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-7e5bf8a5e60d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mLaptops\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mLaptops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Titles\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTitles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mLaptops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Ratings\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRatings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mLaptops\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Prices\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPrices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mLaptops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3039\u001b[0m             \u001b[1;31m# set column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3040\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3114\u001b[0m         \"\"\"\n\u001b[0;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3116\u001b[1;33m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3117\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[1;34m(self, key, value, broadcast)\u001b[0m\n\u001b[0;32m   3762\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3763\u001b[0m             \u001b[1;31m# turn me into an ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3764\u001b[1;33m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3765\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3766\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    745\u001b[0m     \"\"\"\n\u001b[0;32m    746\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 747\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m    748\u001b[0m             \u001b[1;34m\"Length of values \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[1;34mf\"({len(data)}) \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (0) does not match length of index (10)"
     ]
    }
   ],
   "source": [
    "#creating dataframe        \n",
    "Laptops=pd.DataFrame({})\n",
    "Laptops[\"Titles\"]=Titles[:10]\n",
    "Laptops[\"Ratings\"]=Ratings\n",
    "Laptops[\"Prices\"]=Prices[:10]\n",
    "Laptops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in ratings_tags:\n",
    "        rating=i.text\n",
    "        ratings.append(rating)\n",
    "\n",
    "for i in price_tags:\n",
    "        prices=i.text\n",
    "        price.append(prices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
